{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.\n",
    "For each regular expression `rexpr` and the corresponding string `s` in the following table, indicate the span of string `s` that is matched by `rexpr` (i.e., the output of `re.search(rexpr, s)` in Python).\n",
    "\n",
    "| rexpr | s        |\n",
    "|-------|----------|\n",
    "| ha*   | hahaha   |\n",
    "| ha*   | haaa     |\n",
    "| ha*   | hihahaha |\n",
    "| (ha)* | hahaha   |\n",
    "| (ha)* | haaa     |\n",
    "| (ha)* | hihahaha |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='ha'>\n",
      "<re.Match object; span=(0, 4), match='haaa'>\n",
      "<re.Match object; span=(0, 1), match='h'>\n",
      "<re.Match object; span=(0, 6), match='hahaha'>\n",
      "<re.Match object; span=(0, 2), match='ha'>\n",
      "<re.Match object; span=(0, 0), match=''>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "rexprs = ['ha*'] * 3 + ['(ha)*'] * 3\n",
    "ss = ['hahaha', 'haaa', 'hihahaha', 'hahaha', 'haaa', 'hihahaha']\n",
    "\n",
    "table = pd.DataFrame({'rexpr': rexprs, 's': ss})\n",
    "\n",
    "for index, row in table.iterrows():\n",
    "    rexpr = row['rexpr']\n",
    "    s = row['s']\n",
    "    match = re.search(rexpr, s)\n",
    "    if match:\n",
    "        print(match)\n",
    "        # print(f\"Match found for rexpr '{rexpr}' in string '{s}' at span {match.span()}\")\n",
    "    else:\n",
    "        print(f\"No match found for rexpr '{rexpr}' in string '{s}'\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.\n",
    "In Porter stemming algorithm, the matching condition of one of the rewrite rules is that\n",
    "the word to be matched contains a vowel (a, e, i, o, u) before ending with ing. The intent\n",
    "is that when a word satisfies this condition, it is a verb in continuous tense, and so its ing\n",
    "ending can be removed to convert the verb into its base form.\n",
    "\n",
    "Give a regular expression that will match a word that satisfies the above-mentioned\n",
    "condition. Assume that the string to be matched is a word consisting of lowercase letters\n",
    "and digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditions\n",
    "if word includes vowel, and ends with \"ing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passes first condition only\n"
     ]
    }
   ],
   "source": [
    "word='hello'\n",
    "\n",
    "def porter_stemming_algorithm(word):\n",
    "    \"\"\"\n",
    "    NOTE: ### Documentation written partaly using GitHub Copilot for added clarity!!! ### \n",
    "    \n",
    "    Applies the Porter Stemming Algorithm to the given word.\n",
    "\n",
    "    Parameters:\n",
    "    word (str): The word to be stemmed.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    This function checks if the word ends with 'ing' and contains at least one vowel. If both conditions are met, it is assumed to be a verb in continuous tense. If only the second condition is met, it is assumed to be a regular verb. If only the first condition is met, it is assumed to be a word with a vowel.\n",
    "\n",
    "    Examples:\n",
    "    >>> porter_stemming_algorithm('running')\n",
    "    passes first and second condition, probably a verb in continuous tense\n",
    "\n",
    "    >>> porter_stemming_algorithm('run')\n",
    "    passes second condition only\n",
    "\n",
    "    >>> porter_stemming_algorithm('apple')\n",
    "    passes first condition only\n",
    "    \"\"\"\n",
    "    if any(vowel in word for vowel in ['a', 'e', 'i', 'o', 'u']) and word.endswith('ing'):\n",
    "        print('passes first and second condition, probably a verib in continious tense')\n",
    "    elif any(vowel in word for vowel in ['a', 'e', 'i', 'o', 'u']):\n",
    "        print('passes first condition only')\n",
    "    elif word.endswith('ing'):\n",
    "        print('passes second condition only')\n",
    "\n",
    "porter_stemming_algorithm(word=word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.\n",
    "### 3. Let the training text be:\n",
    "`tin singing sterling jest lingo singing jest singing tin`\n",
    "\n",
    "Give a trace of the byte-pair encoding (BPE) algorithm given the above training text, where the number of merges `k = 4`. Show the merge operation and the resulting vocabulary in each step of the algorithm. If there is a tie in the choice of merge operations, a merge operation that results in a merged token with the smallest number of characters is preferred.\n",
    "\n",
    "For each of the following strings, show the tokenized string by applying the token segmenter learned:\n",
    "\n",
    "(a) `ingest`  \n",
    "(b) `sting`  \n",
    "(c) `interest`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is BPE, and how does one implement it?\n",
    "[GeeksForGeeks](https://www.geeksforgeeks.org/byte-pair-encoding-bpe-in-nlp/)\n",
    "1. Initialize the vocabulary with all the bytes or characters in the text corpus\n",
    "2. Calculate the frequency of each byte or character in the text corpus.\n",
    "3. Repeat the following steps until the desired vocabulary size is reached:\n",
    "    1. Find the most frequent pair of consecutive bytes or characters in the text corpus\n",
    "    2. Merge the pair to create a new subword unit.\n",
    "    3. Update the frequency counts of all the bytes or characters that contain the merged pair.\n",
    "4. Add the new subword unit to the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "\n",
    "class BytePairEncoding:\n",
    "    \"\"\"\n",
    "    Implements the Byte Pair Encoding (BPE) algorithm for tokenizing text by iteratively merging the most frequent pairs of symbols.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus: str):\n",
    "        \"\"\"\n",
    "        Initializes the BPE model with a corpus.\n",
    "\n",
    "        :param corpus: A string containing the training text for BPE.\n",
    "        \"\"\"\n",
    "        self.corpus = corpus\n",
    "        self._vocab = self._get_initial_vocab()\n",
    "        self.merges = []  # To store the order of merges\n",
    "\n",
    "    def _get_initial_vocab(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Builds the initial vocabulary from the corpus. Each word in the corpus is split into characters, and each character\n",
    "        sequence is considered as an initial token.\n",
    "\n",
    "        :return: A dictionary where keys are tokenized words and values are their frequencies in the corpus.\n",
    "        \"\"\"\n",
    "        vocab = defaultdict(int)\n",
    "        for word in self.corpus.split():\n",
    "            # Each character in the word is separated by a space to form the initial vocabulary\n",
    "            vocab[\" \".join(list(word))] += 1\n",
    "        return vocab\n",
    "\n",
    "    def _get_stats(self) -> Dict[Tuple[str, str], int]:\n",
    "        \"\"\"\n",
    "        Calculates the frequency of each pair of consecutive symbols in the vocabulary.\n",
    "\n",
    "        :return: A dictionary where keys are pairs of symbols and values are their frequencies.\n",
    "        \"\"\"\n",
    "        pairs = defaultdict(int)\n",
    "        for word, freq in self._vocab.items():\n",
    "            symbols = word.split()\n",
    "            for i in range(len(symbols) - 1):\n",
    "                # Count the frequency of each adjacent pair of symbols\n",
    "                pairs[symbols[i], symbols[i + 1]] += freq\n",
    "        return pairs\n",
    "\n",
    "    def _merge_vocab(self, pair: Tuple[str, str]) -> None:\n",
    "        \"\"\"\n",
    "        Merges the most frequent pair of symbols in the vocabulary.\n",
    "\n",
    "        :param pair: A tuple representing the pair of symbols to be merged.\n",
    "        \"\"\"\n",
    "        v_out = {}\n",
    "        bigram = re.escape(\" \".join(pair))\n",
    "        p = re.compile(r\"(?<!\\S)\" + bigram + r\"(?!\\S)\")\n",
    "\n",
    "        for word in self._vocab:\n",
    "            # Replace the most frequent pair with its merged form in the vocabulary\n",
    "            w_out = p.sub(\"\".join(pair), word)\n",
    "            v_out[w_out] = self._vocab[word]\n",
    "\n",
    "        self._vocab = v_out\n",
    "        self.merges.append(pair)  # Store the merge operation\n",
    "\n",
    "    def train(self, n: int) -> None:\n",
    "        \"\"\"\n",
    "        Performs the BPE algorithm for a specified number of merges.\n",
    "\n",
    "        :param n: The number of merge operations to perform.\n",
    "        \"\"\"\n",
    "        print(f\"Initial Vocabulary: {self._vocab}\\n\")\n",
    "\n",
    "        for i in range(n):\n",
    "            pairs = self._get_stats()\n",
    "            if not pairs:\n",
    "                break  # No more pairs to merge\n",
    "\n",
    "            # Find the most frequent pair and handle ties\n",
    "            max_freq = max(pairs.values())\n",
    "            best_pairs = [pair for pair in pairs if pairs[pair] == max_freq]\n",
    "\n",
    "            # Tie-breaking: choose the pair that results in the smallest merged token\n",
    "            best = min(best_pairs, key=lambda x: len(\"\".join(x)))\n",
    "\n",
    "            self._merge_vocab(best)\n",
    "\n",
    "            print(f\"Step {i + 1}: Merge {best} -> Vocabulary: {self._vocab}\\n\")\n",
    "\n",
    "    def tokenize(self, word: str) -> str:\n",
    "        \"\"\"\n",
    "        Tokenizes a new word using the learned BPE merges.\n",
    "\n",
    "        :param word: The word to tokenize.\n",
    "        :return: The tokenized version of the word.\n",
    "        \"\"\"\n",
    "        word = (\n",
    "            \" \".join(list(word)) + \" </w>\"\n",
    "        )  # Initialize the word with spaces between characters\n",
    "        for merge in self.merges:\n",
    "            bigram = \" \".join(merge)\n",
    "            word = re.sub(r\"\\b\" + bigram + r\"\\b\", \"\".join(merge), word)\n",
    "        return word.replace(\"</w>\", \"\")\n",
    "\n",
    "    @property\n",
    "    def vocab(self) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Returns the current vocabulary after training.\n",
    "\n",
    "        This property ensures that the vocabulary is accessed in a read-only manner.\n",
    "\n",
    "        :return: The vocabulary dictionary after BPE merges.\n",
    "        \"\"\"\n",
    "        return self._vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Vocabulary: defaultdict(<class 'int'>, {'t i n': 2, 's i n g i n g': 3, 's t e r l i n g': 1, 'j e s t': 2, 'l i n g o': 1})\n",
      "\n",
      "Step 1: Merge ('i', 'n') -> Vocabulary: {'t in': 2, 's in g in g': 3, 's t e r l in g': 1, 'j e s t': 2, 'l in g o': 1}\n",
      "\n",
      "Step 2: Merge ('in', 'g') -> Vocabulary: {'t in': 2, 's ing ing': 3, 's t e r l ing': 1, 'j e s t': 2, 'l ing o': 1}\n",
      "\n",
      "Step 3: Merge ('s', 't') -> Vocabulary: {'t in': 2, 's ing ing': 3, 'st e r l ing': 1, 'j e st': 2, 'l ing o': 1}\n",
      "\n",
      "Step 4: Merge ('s', 'ing') -> Vocabulary: {'t in': 2, 'sing ing': 3, 'st e r l ing': 1, 'j e st': 2, 'l ing o': 1}\n",
      "\n",
      "Final Vocabulary: {'t in': 2, 'sing ing': 3, 'st e r l ing': 1, 'j e st': 2, 'l ing o': 1}\n"
     ]
    }
   ],
   "source": [
    "corpus = \"tin singing sterling jest lingo singing jest singing tin\"\n",
    "n = 4\n",
    "\n",
    "bpe = BytePairEncoding(corpus)\n",
    "bpe.train(n)\n",
    "final_vocab = bpe.vocab\n",
    "\n",
    "print(f\"Final Vocabulary: {final_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 'ingest': ing e st \n",
      "Tokenized 'sting': st ing \n",
      "Tokenized 'interest': in t e r e st \n"
     ]
    }
   ],
   "source": [
    "tokenized_a = bpe.tokenize(\"ingest\")\n",
    "tokenized_b = bpe.tokenize(\"sting\")\n",
    "tokenized_c = bpe.tokenize(\"interest\")\n",
    "\n",
    "print(f\"Tokenized 'ingest': {tokenized_a}\")\n",
    "print(f\"Tokenized 'sting': {tokenized_b}\")\n",
    "print(f\"Tokenized 'interest': {tokenized_c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
